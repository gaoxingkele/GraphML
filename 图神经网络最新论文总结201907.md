Crystal Graph Neural Networks for Data Mining in Materials Science (Arxiv 2019)
本文提出了一种晶体图形神经网络方法，没有键距，并且引入了一个尺度不变图协调器。CGNN模型预测测试材料的形成能、单位电池体积、带隙和总磁化强度等体积特性，平均误差小于数据库的对应数据。 本文的代码可以在github[2]找到。

Explainability Techniques for Graph Convolutional Networks (ICML 2019)[3]
作者假设一般形式的图网络（GN）定义，在解释算法时考虑两个主要的类，基于梯度的和基于分解的。讨论的基础是一个测试数据集和一个化学任务。 论文主要工作是重点研究 GN 的解释性技术，比较了基于图的任务预测的两种主要的可解释性方法，该论文也给出了github代码[4]。

Semi-Supervised Graph Classification: A Hierarchical Graph Perspective (WWW 2019)[5]
这是腾讯AI实验室发表的有关图模型论文，本文研究了节点分类问题层次图，其中"节点"是一个图形实例，例如一个用户组。 针对现实数据中标记数据的局限性，设计了两种新的半监督解决方案：基于谨慎 / 主动迭代的半监督图分类(简称 sel-c / ai)。 Sel-c / ai 采用了一种迭代框架，它轮流构建或更新两个分类器，其中一个在图实例级别，另一个在层次图中。 为了简化层次图的表示，本文提出了一种新的层次图表示方法，提出了一种新的有监督自加权图嵌入方法，它将任意大小的图形实例嵌入到定长向量。 通过合成数据的实验和腾讯 QQ 群数据，他们证明 sel-c / ai 表现更好，该论文也给出了github代码[6]。

Capsule Graph Neural Network (ICLR 2019)[7]
本文提出了胶囊图神经网络(CapsGNN) ，它采用胶囊的概念来解决现有基于胶囊的图嵌入算法的不足。 通过以胶囊的形式提取节点特征，可以利用路由机制在图的层次上获取重要信息。 因此该模型为每个图生成多个嵌入，以从不同方面捕获图的属性。 Capsgnn 中的注意力模块用于处理不同大小的图，这也使模型能够关注图的关键部分。论文作者对10个图结构化数据集的评估表明，CapsGNN 有一个强大的机制，可以通过数据驱动捕获整个图的宏观属性。 借助于该新工具，在多项图形分类任务中，比先前技术性能更好，该论文也给出了github代码[8]。

How Powerful are Graph Neural Networks? (ICLR 2019)[9]
论文作者提出了一个理论框架来分析 gnn 捕获不同图结构的表达能力。 他们的结果刻画了流行的 GNN 变体，如图卷积网络和图形网络的鉴别能力，并表明他们不能学会区分某些简单的图结构。 作者开发了一个简单的架构，证明它是 gnn 类中表达能力最强的，并且与 Weisfeiler-Lehman 图同构测试一样强大。 在一些图形分类基准上实证验证了他们的模型实现了最先进的性能，该论文也给出了github代码[10]。

Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks (AAAI 2019)[11]
该论文提出了一个广义的 gnn，即所谓的 k 维Gnn (k-GNNs) ，它采用高阶图结构和分子图。这些高阶结构在社交网络中扮演着重要的角色，实验证明在图形分类和回归中是有用的。该论文也给出了github代码[12]。

Capsule Neural Networks for Graph Classification using Explicit Tensorial Graph Representations (Arxiv 2019)[13]
该论文通过从给定集合中的每个图中提取固定大小的张量信息，并使用胶囊网络进行图分类。这里考虑的图是无向的，并且在节点上具有明确的特征。 使用标准基准化学和蛋白质数据集，论文证明了图胶囊网络分类模型使用一个明确的张量表示的图是有竞争力，尽管只有有限的超参数搜索。该论文也给出了github代码[14]。

Three-Dimensionally Embedded Graph Convolutional Network for Molecule Interpretation (Arxiv 2018)[15]
该论文提出了一种基于三维分子图的预测分子性质和生化活性的三维图形卷积网络(3DGCN)。 在3DGCN 中，图卷积与向量上的学习操作统一起来处理分子拓扑的空间信息。 与其他深度学习模型相比，3DGCN 模型在各种任务上显示出更高的性能，不论其在3D 空间中的旋转情况如何，都可以将给定的参数概括为目标特征。 更重要的是该模型还可以区分一个分子的三维旋转和预测目标值。该论文也给出了github代码[16]。

Learning Graph-Level Representations with Recurrent Neural Networks (Arxiv 2018)[17]
论文作者开发了一种新的方法来学习图层表示，其中包括无监督和监督式学习组件的组合。 首先以无监督的方式学习一组节点表示。 采用 Gumbel-Softmax 分布近似的随机游走方法，将图节点映射为节点序列。 循环神经网络单元(RNN)被修改以适应节点表示及其邻域信息。 在标准图分类基准上的实验表明，该方法在收敛速度和分类精度方面比最新的算法具有更好或可比的性能。 该论文也给出了github代码[18]。

Graph Capsule Convolutional Neural Networks (ICML 2018)[19]
本文用 hinton2011变换中提出的一种简化思想，揭示了（Graph Convolutional Neural Networks）GCNN 模型的一些基本缺陷，论文提出了 GCAPS-CNN 图形简化网络模型。 另外，我们还设计了 （Graph Capsule Network）GCAPS-CNN 模型来解决当前 GCNN 模型所面临的特殊的图分类问题。 该论文提出的图胶囊网络能够明显优于之前的深度学习方法和图形分类基准数据集上的图形核函数。该论文也给出了github代码 [20]。

Graph Classification Using Structural Attention (KDD 2018)[21]
本文研究了基于attention的图分类问题。 将attention集中在图中细小但信息丰富的部分，从而避免图其余部分的噪点。 论文提出了一种新的 RNN 模型，称为图attention模型(GAM) ，它只处理图的一部分，通过自适应地选择一个序列的"信息"节点。 在多个实际数据集上的实验结果表明，该方法在图分类中具有很强的竞争力。该论文也给出了github代码[22]。

Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation (NIPS 2018)[23]
分子图生成的目标是发现具有所需特性的新分子，如药物相似性和合成可及性，同时遵守物理定律，如化学价。 然而，设计模型，以找到分子优化所需的性质，同时纳入高度复杂和不可微的规则仍然是一个具有挑战性的任务。论文提出了图卷积策略网络(GCPN) ，一个通用的基于图卷积网络的模型，用于通过强化学习生成目标定向图。 该模型通过策略梯度来优化特定领域的奖励和对抗性损失，并在一个包含特定领域规则的环境中运行。 实验结果表明，与已知分子相比，GCPN 在化学性能优化方面比现有基线提高了61% ，在约束性能优化方面提高了184% 。该论文也给出了github代码[24]。

Hierarchical Graph Representation Learning with Differentiable Pooling (NIPS 2018)[25]
该论文提出 DIFFPOOL，一个可微图形池模块，可以生成图的层次表示，并可以结合各种图神经网络体系结构的端到端的方式。 Diffpool 为深层 GNN 的每一层的节点学习一个可微软集群分配，将节点映射到一组集群，然后这些集群形成下一个 GNN 层的粗化输入。 实验结果表明，将 GNN 方法与 DIFFPOOL 相结合，比图分类基准的准确率平均提高了5-10% ，在五个基准数据集中的四个方面实现了新的最先进水平。该论文也给出了github代码[26]。

更多信息请关注微信公众号：水木AI

参考
https://storage.googleapis.com/rimcs_cgnn/cgnn_matsci_May_27_2019.pdf
https://storage.googleapis.com/rimcs_cgnn/cgnn_matsci_May_27_2019.pdf
https://128.84.21.199/pdf/1905.13686.pdf
https://github.com/gn-exp/gn-exp
https://arxiv.org/pdf/1904.05003.pdf
https://github.com/benedekrozemberczki/SEAL-CI
https://openreview.net/forum?id=Byl8BnRcYm
https://github.com/benedekrozemberczki/CapsGNN
https://arxiv.org/abs/1810.00826
https://github.com/weihua916/powerful-gnns
https://arxiv.org/pdf/1810.02244v2.pdf
https://github.com/k-gnn/k-gnn
https://arxiv.org/pdf/1902.08399v1.pdf
https://github.com/BraintreeLtd/PatchyCapsules
https://arxiv.org/abs/1811.09794
https://github.com/blackmints/3DGCN
https://arxiv.org/pdf/1805.07683v4.pdf
https://github.com/yuj-umd/graphRNN
https://arxiv.org/abs/1805.08090
https://github.com/vermaMachineLearning/Graph-Capsule-CNN-Networks
http://ryanrossi.com/pubs/KDD18-graph-attention-model.pdf
https://github.com/benedekrozemberczki/GAM
https://arxiv.org/abs/1806.02473
https://github.com/bowenliu16/rl_graph_generation
http://papers.nips.cc/paper/7729-hierarchical-graph-representation-learning-with-differentiable-pooling.pdf
https://github.com/rusty1s/pytorch_geometric
